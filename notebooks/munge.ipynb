{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Summarizer for Product Reviews\n",
    "* Build an LLM that can generate concise and informative summaries for product reviews. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Hugging Face\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer,Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extractive summarization - most important sentences from the original text are selected and combined to form a summary. Transformers in this case are used to process the text, extract features and perform sentence ranking\n",
    "2. Abstractive summarization - a new summary is generated by understanding the context of the original text and generating new phrases and sentences that summarise its content e.g encoder-decoder models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['cat', 'group_id', 'rev1', 'rev2', 'rev3', 'rev4', 'rev5', 'rev6', 'rev7', 'rev8', 'summ1', 'summ2', 'summ3', 'rating1', 'rating2', 'rating3', 'rating4', 'rating5', 'rating6', 'rating7', 'rating8'],\n",
       "        num_rows: 28\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['cat', 'group_id', 'rev1', 'rev2', 'rev3', 'rev4', 'rev5', 'rev6', 'rev7', 'rev8', 'summ1', 'summ2', 'summ3', 'rating1', 'rating2', 'rating3', 'rating4', 'rating5', 'rating6', 'rating7', 'rating8'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['cat', 'group_id', 'rev1', 'rev2', 'rev3', 'rev4', 'rev5', 'rev6', 'rev7', 'rev8', 'summ1', 'summ2', 'summ3', 'rating1', 'rating2', 'rating3', 'rating4', 'rating5', 'rating6', 'rating7', 'rating8'],\n",
       "        num_rows: 12\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('../aws_data',data_files={'train':'train.csv','val':'val.csv','test':'test.csv'},sep='\\t')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This pendant is so unique!! The design is beautiful and the bail is a ring instead of the typical bail which gives it a nice touch!! All the corners are smooth and my daughter loves it - looks great on her.I cannot say anything about the chain because used our own chain.:) Satisfied.\n",
      "This silver chain and pendant are elegant and unique. The necklace is very well made, making it a great buy for the cost, and is of high enough quality to be worn every day. The necklace looks beautiful when worn bringing many compliments. Overall, it is highly recommended.\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['rev1'][0])\n",
    "print(dataset['train']['summ1'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_columns = [f\"rating{i+1}\" for i in range(8)]\n",
    "rev_columns = [f\"rev{i+1}\" for i in range(8)]\n",
    "\n",
    "def merge_reviews(example):\n",
    "    #merge reviews into one column\n",
    "    example['reviews'] = '\\n'.join(str(example[col]) for col in rev_columns)\n",
    "    return example\n",
    "\n",
    "#randomly combine summaries into one column, random to reduce bias\n",
    "def combine_summaries(row):\n",
    "    summaries = [row[\"summ1\"], row[\"summ2\"], row[\"summ3\"]]\n",
    "    np.random.seed(42)\n",
    "    return np.random.choice(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['reviews', 'summaries'],\n",
       "        num_rows: 28\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['reviews', 'summaries'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['reviews', 'summaries'],\n",
       "        num_rows: 12\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the map function to apply the merge_reviews and combine_summaries functions to each example in each split\n",
    "clean_dataset = dataset.map(merge_reviews)\n",
    "clean_dataset = clean_dataset.remove_columns(rev_columns+rating_columns)\n",
    "clean_dataset = clean_dataset.map(lambda example: {\"summaries\":combine_summaries(example)}, remove_columns=[\"cat\",\"group_id\",\"summ1\", \"summ2\", \"summ3\"])\n",
    "clean_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'These are very comfortable, quality shoes that can be worn casually. They are functional and incredibly light-weight. However, the shoes tend to run a bit large. Overall, this quality product is recommended.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset['train']['summaries'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero Shot Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name='google/flan-t5-base'\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following product reviews.\n",
      "\n",
      "Took a long time to get and when I finally got them, they didn't seem to work to well joined up (I have 3). Also, they should have come with DC chargers, they don't seem to work well with batteries, imho.\n",
      "The units work fine and the setup is described in the manual works well. The one thing that my wife and I do not like is the Audio. Sounds like you are in a box. The calling button is also a bit strange. It first beeps and then you can speak. The distance it covers is very good.\n",
      "Don't waste your money on these. Although if you try hard enough you can make out what the other person is saying, the audio quality is extremely poor, as is the noise cancellation (if any), and the general sound quality. I wish I had saved the boxes. I'd be sending these back.\n",
      "And the problem is having to wake the kids up in the morning to go to school. They are upstairs and I used to have to trek up and down a couple of times each morning. We put one in each bedroom, 1 in the living room and 1 in the study. Problem solved.\n",
      "We use it in our office to tell another employee if they have a call on hold, but that is about all it is good for. Don't bother trying to have a conversation, clarity is too poor. I didn't realize until after the fact that I should have just bought walkie talkies. At least battery life in these are good.\n",
      "I searched extensively for an intercom for my large two floor home. I selected this unit (ordering three units) and regret my decision. It was very difficult set up and doesnot work that well. I wish I could get a refund as we never use it. My search continues.\n",
      "It is simple to program and operate, which is just what I was looking for. I just wish I didn't have to buy a power cord separately. I am running it on batteries right now, but I am not sure how long they will last.\n",
      "I've spent hours already trying to set up my network and get this system going. The engineering leaves much to be desired. Can't get it to work as advertised. The Manual is one of the least helpful such documents I've ever seen.\n",
      "\n",
      "Summary:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "This intercom is difficult to set up and the manual that comes with it is lacking in help. Audio is poor and sound quality isn't great, background noise is picked up greatly. Batteries are supplied, but a power cord needs to be purchased separately.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "The units work fine and the setup is described in the manual works well. The one thing that my wife and I do not like is the Audio. Sounds like you are in a box. The calling button is also a bit strange. It first beeps and then you can speak. The distance it covers is very good.\n"
     ]
    }
   ],
   "source": [
    "review = clean_dataset['train']['reviews'][10]\n",
    "summary = clean_dataset['train']['summaries'][10]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following product reviews.\n",
    "\n",
    "{review}\n",
    "\n",
    "Summary:\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    original_model.generate(\n",
    "        inputs['input_ids'], max_new_tokens = 200)[0],\n",
    "        skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero-shot (BART) doesn't do a great job at summarizing the reviews, if anything, it just copied and oasted the second review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_prompt = 'Summarize the following product reviews:\\n\\n'\n",
    "end_prompt = \"\\n\\nSummary: \"\n",
    "def tokenize_function(examples):\n",
    "    inputs = [start_prompt + rev + end_prompt for rev in examples[\"reviews\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length= 1024, padding='max_length', truncation=True)\n",
    "    model_inputs[\"labels\"] = tokenizer(text_target=examples[\"summaries\"],max_length=128, padding='max_length', truncation=True).input_ids\n",
    "    #labels = tokenizer(text_target=examples[\"summaries\"], max_length=128, truncation=True)\n",
    "    #model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421dc082da5f406c97bc71a684c6b66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d697553984d4bcca0fb6088e555948f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0deb15ed4a84b46801b342fb3e82b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 28\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 12\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data = clean_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_data = tokenized_data.remove_columns(['reviews','summaries'])\n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-Tune the Model with the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "#Data collators are objects that will form a batch by using a list of dataset elements as input. \n",
    "#To be able to build batches, data collators may apply some processing (like padding).\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e42d801cb3a4c69a05e5b1c21f4cb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8029cf444bba41168a3a691ee46f9186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.831182479858398, 'eval_rouge1': 0.3711, 'eval_rouge2': 0.1033, 'eval_rougeL': 0.2337, 'eval_rougeLsum': 0.2353, 'eval_gen_len': 79.0, 'eval_runtime': 312.7734, 'eval_samples_per_second': 0.038, 'eval_steps_per_second': 0.01, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b13adbb4ef946b5b75be8584aa02cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.7244367599487305, 'eval_rouge1': 0.3884, 'eval_rouge2': 0.1144, 'eval_rougeL': 0.2474, 'eval_rougeLsum': 0.2481, 'eval_gen_len': 79.6667, 'eval_runtime': 322.8665, 'eval_samples_per_second': 0.037, 'eval_steps_per_second': 0.009, 'epoch': 2.0}\n",
      "{'train_runtime': 1918.0751, 'train_samples_per_second': 0.029, 'train_steps_per_second': 0.007, 'train_loss': 5.267559051513672, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14, training_loss=5.267559051513672, metrics={'train_runtime': 1918.0751, 'train_samples_per_second': 0.029, 'train_steps_per_second': 0.007, 'train_loss': 5.267559051513672, 'epoch': 2.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"revs_summarizer_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../models/bart_summ_tokenizer\\\\tokenizer_config.json',\n",
       " '../models/bart_summ_tokenizer\\\\special_tokens_map.json',\n",
       " '../models/bart_summ_tokenizer\\\\vocab.json',\n",
       " '../models/bart_summ_tokenizer\\\\merges.txt',\n",
       " '../models/bart_summ_tokenizer\\\\added_tokens.json',\n",
       " '../models/bart_summ_tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../models/bart_summ_model\")\n",
    "tokenizer.save_pretrained(\"../models/bart_summ_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['reviews', 'summaries'],\n",
       "        num_rows: 28\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['reviews', 'summaries'],\n",
       "        num_rows: 20\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['reviews', 'summaries'],\n",
       "        num_rows: 12\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>human_baseline_summaries</th>\n",
       "      <th>model_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I chose it because it's a beautiful purse, but...</td>\n",
       "      <td>This is a beautiful purse, but it lacks durabi...</td>\n",
       "      <td>This is a great purse, but the straps are too ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These are the perfect tights for my 5-year old...</td>\n",
       "      <td>Great soft feeling fabric and beautiful color ...</td>\n",
       "      <td>These tights are great tights for ballet tight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The shoes are the perfect fit for me. They sup...</td>\n",
       "      <td>These are very stylish, well-fitting, supporti...</td>\n",
       "      <td>The Reebok Reeboks are very comfortable and ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The description say it long... NOT so it is av...</td>\n",
       "      <td>This is a good looking and comfortable tank to...</td>\n",
       "      <td>This is a basic tank top that fits well but is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My son is 3 and this fits him perfectly. He'll...</td>\n",
       "      <td>This Thomas the Tank costume is perfect for sm...</td>\n",
       "      <td>This Thomas the train costume is a great fit f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This product recharges my wife's iPhone 4 with...</td>\n",
       "      <td>This solar-powered charger performs inconsiste...</td>\n",
       "      <td>This solar charger works perfectly. It can be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I recently bought this film and slide scanner ...</td>\n",
       "      <td>The results with this scanner are sporadic at ...</td>\n",
       "      <td>The VuPoint Digital Scanner converts negatives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Since I purchased this backpack a month ago, I...</td>\n",
       "      <td>This backpack is compact, durable and can hold...</td>\n",
       "      <td>This camera bag is well made and is comfortabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yes, HP DVD's are DVD's for the better. Better...</td>\n",
       "      <td>These DVDs are good quality from a reliable br...</td>\n",
       "      <td>This product is made by CMC, with id of CMCMAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>of the fact that an SD card is NOT included wi...</td>\n",
       "      <td>Consumers love this camera for its small size ...</td>\n",
       "      <td>This is a great camera that is easy to use and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0  I chose it because it's a beautiful purse, but...   \n",
       "1  These are the perfect tights for my 5-year old...   \n",
       "2  The shoes are the perfect fit for me. They sup...   \n",
       "3  The description say it long... NOT so it is av...   \n",
       "4  My son is 3 and this fits him perfectly. He'll...   \n",
       "5  This product recharges my wife's iPhone 4 with...   \n",
       "6  I recently bought this film and slide scanner ...   \n",
       "7  Since I purchased this backpack a month ago, I...   \n",
       "8  Yes, HP DVD's are DVD's for the better. Better...   \n",
       "9  of the fact that an SD card is NOT included wi...   \n",
       "\n",
       "                            human_baseline_summaries  \\\n",
       "0  This is a beautiful purse, but it lacks durabi...   \n",
       "1  Great soft feeling fabric and beautiful color ...   \n",
       "2  These are very stylish, well-fitting, supporti...   \n",
       "3  This is a good looking and comfortable tank to...   \n",
       "4  This Thomas the Tank costume is perfect for sm...   \n",
       "5  This solar-powered charger performs inconsiste...   \n",
       "6  The results with this scanner are sporadic at ...   \n",
       "7  This backpack is compact, durable and can hold...   \n",
       "8  These DVDs are good quality from a reliable br...   \n",
       "9  Consumers love this camera for its small size ...   \n",
       "\n",
       "                                     model_summaries  \n",
       "0  This is a great purse, but the straps are too ...  \n",
       "1  These tights are great tights for ballet tight...  \n",
       "2  The Reebok Reeboks are very comfortable and ru...  \n",
       "3  This is a basic tank top that fits well but is...  \n",
       "4  This Thomas the train costume is a great fit f...  \n",
       "5  This solar charger works perfectly. It can be ...  \n",
       "6  The VuPoint Digital Scanner converts negatives...  \n",
       "7  This camera bag is well made and is comfortabl...  \n",
       "8  This product is made by CMC, with id of CMCMAG...  \n",
       "9  This is a great camera that is easy to use and...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = clean_dataset['test'][0:10]['reviews']\n",
    "human_baseline_summaries = clean_dataset['test'][0:10]['summaries']\n",
    "\n",
    "model_summaries = []\n",
    "\n",
    "for _, review in enumerate(reviews):\n",
    "    prompt = f\"\"\"\n",
    "Summarize the following product reviews.\n",
    "\n",
    "{review}\n",
    "\n",
    "Summary: \"\"\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    model_outputs = model.generate(input_ids=input_ids, max_new_tokens=100,do_sample=False)\n",
    "    model_text_output = tokenizer.decode(model_outputs[0], skip_special_tokens=True)\n",
    "    model_summaries.append(model_text_output)\n",
    "\n",
    "zipped_summaries = list(zip(reviews,human_baseline_summaries, model_summaries))\n",
    " \n",
    "df = pd.DataFrame(zipped_summaries, columns = ['reviews','human_baseline_summaries', 'model_summaries'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews\n",
      "---------------------------------------------------------------------------------------------------\n",
      "My son is 3 and this fits him perfectly. He'll probably be able to wear it for the next two years if he'd like. It's cute too. The hat is thin, but completes the outfit. And the candy pocket is huge. Perfect! I'm so glad we bought this costume over any other Thomas costume.\n",
      "I ordered this for my 3 yr old for Halloween. He loved it!! The candy catcher in the front is really neat, but probably need to take a pail or something else along also because it can get to be heavy if they get a lot of candy. I was very pleased with the way it fit and everything.\n",
      "Received from Toynk Toys and was very disappointed when I opened the pkg...... very flimsy felt fabric. No 3D sculpted face that I expected. I became creative and added huge googly eyes, pumpkin patch, spiders, bats, and train tracks to the outfit to make it a bit more suitable for my taste.\n",
      "This is a cute costume that we got for my lil cousin and the candy pouch is basically the size of the entire costume so that's p cool. I doubt it would fit up to six years old like it's advertised as, but it's the perfect size for him (age 2)\n",
      "My son looked sooooo cute with this costume on. It was well worth the price in my opinion because, his face light up when he seen it in the package. The whole night he kept saying to the doors he got candy from 'me the train, chuchu!!'\n",
      "I ordered this costume online and it was perfect for my 20 month old son's second Halloween. It was comfortable and he loved the pocket. The size was perfect because it didn't need to be a particular fit. He loved the hat too. Every house we went to trick or treat complimented the outfit too.\n",
      "My 2 year old loved this costume. He went on the Halloween parade at school and everyone said it was very creative that he has his own candy pouch as part of his costume. He also went around the neighborhood and was pretty popular with his Thomas the train look.\n",
      "I was pleasantly surprised at how cute this costume is in person. My 3 year old son LOVED being Thomas for Halloween, and the candy catcher was a great feature. It also looks like it will grow with him, so we may use it again for Halloween next year if he's still Thomas-obsessed!\n",
      "---------------------------------------------------------------------------------------------------\n",
      "human_baseline_summaries\n",
      "---------------------------------------------------------------------------------------------------\n",
      "This Thomas the Tank costume is perfect for small children. It fits most children up to five or six years old, and could even be used multiple times as the child grows. It has a handy pouch on the front that holds a large load of candy. The costume is highly recommended.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "model_summaries\n",
      "---------------------------------------------------------------------------------------------------\n",
      "This Thomas the train costume is a great fit for a young child. The costume is well made and the candy pouch is large enough to fit in any size child. This is a cute costume that will grow with the child and fit well into the next two years. It is not the perfect fit for older children, but it is a good fit for this age group.\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "for col in df.columns:\n",
    "    print(col)\n",
    "    print(dash_line)\n",
    "    print(df[col][idx])\n",
    "    print(dash_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the following product reviews:\n",
      "\n",
      "This product recharges my wife's iPhone 4 with no problem. One downside - it does not have enough juice to charge an iPad. It would benefit from some indication of the percentage charge of the battery. Also, the LED light is VERY bright.\n",
      "The product is great .The issue is that it came broken and I only found out after I had it for a month. There is no was to call there support. Very very bad idea. Will do more research next time .I don't think I would buy it again!!!!\n",
      "I bought this to test it out for charging my phone on AT section hikes. For the added weight, it was a nice-to-have item. I probably wouldn't have it on a through-hike, but it worked well and if you aren't going to have access to a power source for recharging your phone while you're out, it does the job pretty well.\n",
      "This solar charger works perfectly. It can be charged with electricity or solar power making it a great backup for charging devices. For its size I would recommend getting one and putting it in your but out bag for use with e-devices.\n",
      "I ordered this charger to take on safari to South Africa. It is suppose to charge an iPhone and Kindles. It doesn't work with either of mine. It was a waste of money for me. I'm very disappointed.\n",
      "Charges up, charges your devices. The flashlight is really bright. I had to take a star off because the charge battery doesn't hold a charge over a period of time. However don't go cheap, this product is worth the money.\n",
      "This is my first solar charger, so I can't compare it to any others. I will say that the flashlight is extremely bright as noted by others. It seems to do a nice job charging my Droid Bionic but it didn't seem to work on the Kindle Fire.\n",
      "I left it out for 24 hours in direct sun, the lights on the side showing the progress of charging blindly blinked, but the charge gave my iPod only 1 / 10 of full battery. I tried again and placed it in the sun for 2 sunny days straight, again, after multiple annoying blinking signals, it did not charge anything. Returned.\n"
     ]
    }
   ],
   "source": [
    "text = clean_dataset['test']['reviews'][5]\n",
    "review_prompt = start_prompt +text\n",
    "print(review_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the following product reviews:\n",
      "\n",
      "This product recharges my wife's iPhone 4 with no problem. One downside - it does not have enough juice to charge an iPad. It would benefit from some indication of the percentage charge of the battery. Also, the LED light is VERY bright.\n",
      "The product is great .The issue is that it came broken and I only found out after I had it for a month. There is no was to call there support. Very very bad idea. Will do more research next time .I don't think I would buy it again!!!!\n",
      "I bought this to test it out for charging my phone on AT section hikes. For the added weight, it was a nice-to-have item. I probably wouldn't have it on a through-hike, but it worked well and if you aren't going to have access to a power source for recharging your phone while you're out, it does the job pretty well.\n",
      "This solar charger works perfectly. It can be charged with electricity or solar power making it a great backup for charging devices. For its size I would recommend getting one and putting it in your but out bag for use with e-devices.\n",
      "I ordered this charger to take on safari to South Africa. It is suppose to charge an iPhone and Kindles. It doesn't work with either of mine. It was a waste of money for me. I'm very disappointed.\n",
      "Charges up, charges your devices. The flashlight is really bright. I had to take a star off because the charge battery doesn't hold a charge over a period of time. However don't go cheap, this product is worth the money.\n",
      "This is my first solar charger, so I can't compare it to any others. I will say that the flashlight is extremely bright as noted by others. It seems to do a nice job charging my Droid Bionic but it didn't seem to work on the Kindle Fire.\n",
      "I left it out for 24 hours in direct sun, the lights on the side showing the progress of charging blindly blinked, but the charge gave my iPod only 1 / 10 of full battery. I tried again and placed it in the sun for 2 sunny days straight, again, after multiple annoying blinking signals, it did not charge anything. Returned.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Human Summary:\n",
      " This solar-powered charger performs inconsistently, charging some devices fully but failing to properly charge others. The LED flashlight is too bright  and there is no accurate display of charge level. It's not reliable enough for everyday use, but can be convenient for long trips without a consistent access to a power source.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Model Summary:\n",
      " This solar charger works perfectly. It can be charged with electricity or solar power making it a great backup for charging devices. It does not have enough juice to charge an iPad. It would benefit from some indication of the percentage charge of the battery. The flashlight is extremely bright as noted by others.\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"../models/summ_tokenizer\")\n",
    "inputs = tokenizer(review_prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(\"../models/summ_model\")\n",
    "outputs = model.generate(inputs, max_new_tokens=80, do_sample=False)\n",
    "\n",
    "print(review_prompt)\n",
    "print(dash_line)\n",
    "print('Human Summary:\\n',clean_dataset['test']['summaries'][5])\n",
    "print(dash_line)\n",
    "print('Model Summary:\\n', tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 406290432\n",
      "all model parameters: 406290432\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(original_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation with ROUGE Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\ml_env\\lib\\site-packages\\datasets\\load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART Model Results: \n",
      " {'rouge1': AggregateScore(low=Score(precision=0.2996058040231507, recall=0.4125435160476389, fmeasure=0.3479670127261747), mid=Score(precision=0.33958729071520244, recall=0.46723289597896533, fmeasure=0.38983783736963784), high=Score(precision=0.3757346822644893, recall=0.5255026904934822, fmeasure=0.42718663208307767)), 'rouge2': AggregateScore(low=Score(precision=0.06312952562021687, recall=0.08265921840434287, fmeasure=0.0720059721877162), mid=Score(precision=0.09082496023088557, recall=0.12509826572138288, fmeasure=0.10463030289492095), high=Score(precision=0.12028449871199387, recall=0.17830552220888354, fmeasure=0.1426202125379947)), 'rougeL': AggregateScore(low=Score(precision=0.17449850192537536, recall=0.2353347013393347, fmeasure=0.2001341864041679), mid=Score(precision=0.19933670746470106, recall=0.27537028494137017, fmeasure=0.2293013360437636), high=Score(precision=0.22525622845569337, recall=0.3143351405262885, fmeasure=0.25982343943412983)), 'rougeLsum': AggregateScore(low=Score(precision=0.17423033057879575, recall=0.2321696016407635, fmeasure=0.19993568306447057), mid=Score(precision=0.1989191793271708, recall=0.27300010351873616, fmeasure=0.22886544449464924), high=Score(precision=0.22387782084093177, recall=0.31819967092841067, fmeasure=0.2595337220312237))}\n"
     ]
    }
   ],
   "source": [
    "#compare the human generated summaries with the model summaries\n",
    "rouge_metric = load_metric(\"rouge\")\n",
    "\n",
    "results = rouge_metric.compute(\n",
    "    predictions = model_summaries,\n",
    "    references = human_baseline_summaries,\n",
    "    use_aggregator = True,\n",
    "    use_stemmer = True\n",
    ")\n",
    "\n",
    "print('BART Model Results: \\n', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': {'precision': 0.33958729071520244,\n",
       "  'recall': 0.46723289597896533,\n",
       "  'fmeasure': 0.38983783736963784},\n",
       " 'rouge2': {'precision': 0.09082496023088557,\n",
       "  'recall': 0.12509826572138288,\n",
       "  'fmeasure': 0.10463030289492095},\n",
       " 'rougeL': {'precision': 0.19933670746470106,\n",
       "  'recall': 0.27537028494137017,\n",
       "  'fmeasure': 0.2293013360437636},\n",
       " 'rougeLsum': {'precision': 0.1989191793271708,\n",
       "  'recall': 0.27300010351873616,\n",
       "  'fmeasure': 0.22886544449464924}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = {}\n",
    "for k, v in results.items():\n",
    "    results_dict[k] = {\n",
    "        'precision': v[1][0],\n",
    "        'recall': v[1][1],\n",
    "        'fmeasure': v[1][2]\n",
    "    }\n",
    "\n",
    "results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Precision",
         "type": "bar",
         "x": [
          "rouge1",
          "rouge2",
          "rougeL",
          "rougeLsum"
         ],
         "y": [
          0.33958729071520244,
          0.09082496023088557,
          0.19933670746470106,
          0.1989191793271708
         ]
        },
        {
         "name": "Recall",
         "type": "bar",
         "x": [
          "rouge1",
          "rouge2",
          "rougeL",
          "rougeLsum"
         ],
         "y": [
          0.46723289597896533,
          0.12509826572138288,
          0.27537028494137017,
          0.27300010351873616
         ]
        },
        {
         "name": "Fmeasure",
         "type": "bar",
         "x": [
          "rouge1",
          "rouge2",
          "rougeL",
          "rougeLsum"
         ],
         "y": [
          0.38983783736963784,
          0.10463030289492095,
          0.2293013360437636,
          0.22886544449464924
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "ROUGE Metrics: Fine-tuned BART Summarization Model"
        },
        "xaxis": {
         "title": {
          "text": "ROUGE Type"
         }
        },
        "yaxis": {
         "title": {
          "text": "Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = ['precision', 'recall', 'fmeasure']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for metric in metrics:\n",
    "    values = [results_dict[key][metric] for key in results_dict]\n",
    "    fig.add_trace(go.Bar(x=list(results_dict.keys()), y=values, name=metric.capitalize()))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ROUGE Metrics: Fine-tuned BART Summarization Model',\n",
    "    xaxis=dict(title='ROUGE Type'),\n",
    "    yaxis=dict(title='Score'),\n",
    "    barmode='group',\n",
    "    template='plotly_dark'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametric Efficient Fine Tuning (PEFT)\n",
    "\n",
    "* PEFT is more efficient that full fine-tuning, especially because it's less memory intensive.\n",
    "* PEFT incorporates LoRA which allows a user to fine-tune their model using fewer compute resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank - determines the dimensionality of the space\n",
    "    lora_alpha=32, #controls the power of the regularization term\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 4718592\n",
      "all model parameters: 411009024\n",
      "percentage of trainable model parameters: 1.15%\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(model, \n",
    "                            lora_config)\n",
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'./peft-review-summary-training-{str(int(time.time()))}'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=1,\n",
    "    max_steps=1    \n",
    ")\n",
    "    \n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26dd762e8f94517b753863396520b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "peft_trainer.train()\n",
    "\n",
    "peft_model_path=\"./peft-review-summary-checkpoint-local\"\n",
    "\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
